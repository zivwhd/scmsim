{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c937af0-4e9f-4909-b5f9-402e3e3f46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "import pandas as pd \n",
    "import inspect\n",
    "import sys, logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # or DEBUG, WARNING, etc.\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    stream=sys.stdout\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d6df6a-065e-4265-a1ff-4fba80984eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_scm(scm, nsamples, **kwargs):\n",
    "    values = dict(N = nsamples)\n",
    "    values.update(kwargs)\n",
    "    \n",
    "    for varname, func in scm.items():\n",
    "        argnames = list(inspect.signature(func).parameters.keys())\n",
    "        logging.info(f\"{varname} : f({argnames})\")\n",
    "        args = { name : values[name] for name in argnames }\n",
    "        values[varname] =func(**args)\n",
    "    return values\n",
    "\n",
    "def reeval_scm_with_do(scm, base, **do):    \n",
    "    values = {}\n",
    "    values.update(base)    \n",
    "    modified = set()\n",
    "    for varname, func in scm.items():\n",
    "        if varname in do:\n",
    "            logging.info(f\"DO {varname}\")\n",
    "            func = do[varname]                            \n",
    "\n",
    "        argnames = list(inspect.signature(func).parameters.keys())                        \n",
    "        if varname not in do and not modified.intersection(argnames):\n",
    "            continue\n",
    "        modified.add(varname)\n",
    "        args = { name : values[name] for name in argnames }\n",
    "        logging.info(f\"{varname} : f({argnames})\")\n",
    "        values[varname] =func(**args)\n",
    "    return values\n",
    "\n",
    "\n",
    "def ground_truth_ate(scm, values, treatment, response):\n",
    "    logging.info(\"Calculating ground truth\")\n",
    "    values_0 =  reeval_scm_with_do(SCM, values, **{treatment : lambda N: torch.zeros(N)})\n",
    "    values_1 =  reeval_scm_with_do(SCM, values, **{treatment : lambda N: torch.ones(N)})\n",
    "    return (values_1[response] - values_0[response]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebabb400-04c1-4e0c-bb3a-54c3389ef09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CondMeanDiff:\n",
    "\n",
    "    def __init__(self, treatment, response):\n",
    "        self.treatment_name = treatment\n",
    "        self.response_name = response\n",
    "\n",
    "    def __call__(self, values):\n",
    "        response = values[self.response_name]\n",
    "        treatment = values[self.treatment_name] \n",
    "        return response[treatment >= 0.5].mean() - response[treatment < 0.5].mean()    \n",
    "\n",
    "\n",
    "class ATEStratified:\n",
    "    def __init__(self, treatment, response, strat_func):\n",
    "        self.treatment_name = treatment\n",
    "        self.response_name = response\n",
    "        self.strat_func = strat_func        \n",
    "\n",
    "    def __call__(self, values):        \n",
    "        response = values[self.response_name]\n",
    "        treatment = values[self.treatment_name]\n",
    "\n",
    "        keys = self.strat_func(values)\n",
    "        unique_keys =set(keys.tolist())\n",
    "        ate = 0.0\n",
    "        total_weight = 0\n",
    "        for k in unique_keys:        \n",
    "            is_treatment = (treatment > 0.5)\n",
    "            treatment_mask = (keys == k) & is_treatment\n",
    "            control_mask = (keys == k) & (~is_treatment)\n",
    "            if (treatment_mask.sum() == 0 or control_mask.sum() == 0):\n",
    "                logging.info(f\"skipping group {k}\")\n",
    "                continue\n",
    "            group_ate = (response[treatment_mask].mean() - response[control_mask].mean())\n",
    "            group_weight = ((keys == k)*1).sum()\n",
    "            total_weight += group_weight\n",
    "            ate = ate + group_ate*group_weight\n",
    "        ate = ate / total_weight\n",
    "        return ate\n",
    "\n",
    "\n",
    "class SplitStratify:\n",
    "    def __init__(self, varname, splits):\n",
    "        self.varname = varname\n",
    "        self.splits = torch.Tensor(splits)\n",
    "\n",
    "    def __call__(self, values):\n",
    "        vals = values[self.varname]\n",
    "        keys = torch.zeros(vals.shape)\n",
    "        for bar in self.splits:\n",
    "            keys += (vals < bar )\n",
    "        return keys\n",
    "\n",
    "class QuantStratify:\n",
    "    def __init__(self, varname, ngroups):\n",
    "        self.varname = varname\n",
    "        self.ngroups = ngroups\n",
    "\n",
    "    def __call__(self, values):\n",
    "        vals = values[self.varname]\n",
    "        keys = torch.zeros(vals.shape)\n",
    "        quantiles = torch.quantile(vals, torch.arange(self.ngroups)[1:]/float(self.ngroups))\n",
    "        for q in quantiles:\n",
    "            keys += (vals <  q)\n",
    "        return keys\n",
    "\n",
    "def enrich_propensity(values, target_name, covariate_names, propensity_name=\"propensity\", model=None):\n",
    "    # Convert target to numpy\n",
    "    y = values[target_name].cpu().numpy()\n",
    "    if y.ndim > 1 and y.shape[1] == 1:\n",
    "        y = y.flatten()\n",
    "\n",
    "    # Concatenate covariates (converted to numpy)\n",
    "    X = torch.stack([values[name] for name in covariate_names]).numpy().transpose()    \n",
    "    # Create and fit sklearn logistic regression\n",
    "    if model is None:\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "    logging.info(f\"fitting model for propensity: '{propensity_name}'\")\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Predict probabilities (for positive class)\n",
    "    probs = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Convert back to torch tensor\n",
    "    probs_tensor = torch.from_numpy(probs).float()\n",
    "    values[propensity_name] = probs_tensor\n",
    "\n",
    "class ATEPropensity:\n",
    "\n",
    "    def __init__(self, treatment, response, propensity):\n",
    "        self.treatment_name = treatment\n",
    "        self.response_name = response\n",
    "        self.propensity_name = propensity\n",
    "\n",
    "    def __call__(self, values):\n",
    "        response = values[self.response_name]\n",
    "        treatment = values[self.treatment_name] \n",
    "        prop = values[self.propensity_name]\n",
    "        \n",
    "        treatment_mask = (treatment >= 0.5)\n",
    "        \n",
    "        return (\n",
    "            (response[treatment_mask]/prop[treatment_mask]).sum() / (1.0/prop[treatment_mask]).sum() -\n",
    "            (response[~treatment_mask]/(1-prop[~treatment_mask])).sum() / (1.0/(1-prop[~treatment_mask])).sum()\n",
    "        )\n",
    "\n",
    "class ATEImpute:\n",
    "\n",
    "    def __init__(self, treatment, response, conditions, mgen=None):\n",
    "        self.treatment_name = treatment\n",
    "        self.response_name = response\n",
    "        self.condition_names = conditions\n",
    "        self.mgen = mgen or (lambda: GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3))\n",
    "        \n",
    "    def __call__(self, values):\n",
    "        response = values[self.response_name]\n",
    "        treatment = values[self.treatment_name] \n",
    "        \n",
    "        y = response.numpy()\n",
    "\n",
    "        # Concatenate covariates (converted to numpy)\n",
    "        X = torch.stack([values[name] for name in [self.treatment_name] + self.condition_names]).numpy().transpose()    \n",
    "        model = self.mgen()\n",
    "        logging.info(f\"fitting model for imputation\")\n",
    "        model.fit(X, y)\n",
    "\n",
    "        treatment_mask = (treatment > 0.5)\n",
    "        treatment_counterfactual_covs = X[(treatment_mask.numpy()), :]        \n",
    "        treatment_counterfactual_covs[:,0] = 0\n",
    "        \n",
    "        treatment_counterfactual_resp = torch.from_numpy(model.predict(treatment_counterfactual_covs)).float()        \n",
    "\n",
    "        control_mask = ~treatment_mask\n",
    "        control_counterfactual_covs = X[(control_mask.numpy()), :]\n",
    "        control_counterfactual_covs[:,0] = 1\n",
    "        control_counterfactual_resp = torch.from_numpy(model.predict(control_counterfactual_covs)).float()        \n",
    "\n",
    "        ate = (\n",
    "            (response[treatment_mask] -  treatment_counterfactual_resp).sum() + \n",
    "            (control_counterfactual_resp - response[control_mask]).sum()) / response.numel()\n",
    "        return ate\n",
    "        \n",
    "\n",
    "def apply_filter(values, mask):\n",
    "    return {k : (v[mask] if type(v) == torch.Tensor else v) for k,v in values.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18d1630-23db-4696-97d9-42600c488e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(**kwargs):\n",
    "    return pd.DataFrame({k:v.unsqueeze(0) for k,v in kwargs.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef914979-30c6-4d9f-98c3-33bc492d0bc9",
   "metadata": {},
   "source": [
    "## Sanity - No causality\n",
    "(Two items of the same gerne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61908177-ab15-42fc-8b48-d9d5b59aef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 18:57:57,043 - INFO - U : f(['N'])\n",
      "2025-07-18 18:57:57,043 - INFO - T : f(['N', 'U'])\n",
      "2025-07-18 18:57:57,043 - INFO - Y : f(['N', 'U', 'T'])\n",
      "2025-07-18 18:57:57,043 - INFO - fitting model for propensity: 'propensity'\n",
      "2025-07-18 18:57:57,113 - INFO - fitting model for imputation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "      <th>ATE_Stratified</th>\n",
       "      <th>ATE_Propensity</th>\n",
       "      <th>ATE_Impute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257818</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.00718</td>\n",
       "      <td>0.007122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Naive  ATE_Stratified  ATE_Propensity  ATE_Impute\n",
       "0  0.257818        0.007118         0.00718    0.007122"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCM = {\n",
    "    \"U\" : lambda N: (torch.rand(N) < 0.5)*1.0,\n",
    "    \"T\" : lambda N, U: (torch.rand(N) < (0.2 + 0.5*U))*1.0,\n",
    "    \"Y\" : lambda N, U, T: (torch.rand(N) < (0.2 + 0.5*U))*1.0\n",
    "}\n",
    "values = eval_scm(SCM, 100000)\n",
    "enrich_propensity(values, \"T\", [\"U\"])#, model=GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3))\n",
    "\n",
    "# GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "show(Naive=CondMeanDiff(\"T\",\"Y\")(values),\n",
    "     ATE_Stratified=ATEStratified(\"T\",\"Y\", SplitStratify(\"U\",[0.5]))(values),\n",
    "     ATE_Propensity=ATEPropensity(\"T\",\"Y\", \"propensity\")(values),\n",
    "     ATE_Impute=ATEImpute(\"T\",\"Y\",[\"U\"])(values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97369f71-c8cf-4062-ba9c-3dec840e680b",
   "metadata": {},
   "source": [
    "## Causality with Confounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2884e8df-31b2-4e38-a30a-8dbd2d247054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 18:57:57,935 - INFO - U : f(['N'])\n",
      "2025-07-18 18:57:57,937 - INFO - T : f(['N', 'U'])\n",
      "2025-07-18 18:57:57,938 - INFO - Y : f(['N', 'U', 'T'])\n",
      "2025-07-18 18:57:57,940 - INFO - fitting model for propensity: 'propensity'\n",
      "2025-07-18 18:57:58,004 - INFO - fitting model for imputation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "      <th>ATE_Stratified</th>\n",
       "      <th>ATE_Propensity</th>\n",
       "      <th>ATE_Impute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.475195</td>\n",
       "      <td>0.202657</td>\n",
       "      <td>0.202756</td>\n",
       "      <td>0.202657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Naive  ATE_Stratified  ATE_Propensity  ATE_Impute\n",
       "0  0.475195        0.202657        0.202756    0.202657"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCM = {\n",
    "    \"U\" : lambda N: (torch.rand(N) < 0.5)*1.0,\n",
    "    \"T\" : lambda N, U: (torch.rand(N) < (0.1 + 0.5*U))*1.0,\n",
    "    \"Y\" : lambda N, U, T: (torch.rand(N) < (0.1 + 0.5*U + 0.2*T))*1.0\n",
    "}\n",
    "values = eval_scm(SCM, 100000)\n",
    "enrich_propensity(values, \"T\", [\"U\"])#, model=GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3))\n",
    "\n",
    "# GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "show(Naive=CondMeanDiff(\"T\",\"Y\")(values),\n",
    "     ATE_Stratified=ATEStratified(\"T\",\"Y\", SplitStratify(\"U\",[0.5]))(values),\n",
    "     ATE_Propensity=ATEPropensity(\"T\",\"Y\", \"propensity\")(values),\n",
    "     ATE_Impute=ATEImpute(\"T\",\"Y\",[\"U\"])(values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5da15-ab0f-40fc-8486-1d8eb8931f86",
   "metadata": {},
   "source": [
    "## Causality with a weak Confounder\n",
    "(For example Godfather-I, Godfather II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e4c5bea-d5d6-43b9-8bde-04e1a0dff03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 18:57:58,770 - INFO - U : f(['N'])\n",
      "2025-07-18 18:57:58,773 - INFO - T : f(['N', 'U'])\n",
      "2025-07-18 18:57:58,774 - INFO - Y : f(['N', 'U', 'T'])\n",
      "2025-07-18 18:57:58,776 - INFO - fitting model for propensity: 'propensity'\n",
      "2025-07-18 18:57:58,843 - INFO - fitting model for imputation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "      <th>ATE_Stratified</th>\n",
       "      <th>ATE_Propensity</th>\n",
       "      <th>ATE_Impute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.526144</td>\n",
       "      <td>0.498129</td>\n",
       "      <td>0.498139</td>\n",
       "      <td>0.498122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Naive  ATE_Stratified  ATE_Propensity  ATE_Impute\n",
       "0  0.526144        0.498129        0.498139    0.498122"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCM = {\n",
    "    \"U\" : lambda N: (torch.rand(N) < 0.5)*1.0,\n",
    "    \"T\" : lambda N, U: (torch.rand(N) < (0.1 + 0.5*U))*1.0,\n",
    "    \"Y\" : lambda N, U, T: (torch.rand(N) < (0.05 + 0.05*U  + 0.5*T))*1.0\n",
    "}\n",
    "values = eval_scm(SCM, 100000)\n",
    "enrich_propensity(values, \"T\", [\"U\"])#, model=GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3))\n",
    "\n",
    "\n",
    "show(Naive=CondMeanDiff(\"T\",\"Y\")(values),\n",
    "     ATE_Stratified=ATEStratified(\"T\",\"Y\", SplitStratify(\"U\",[0.5]))(values),\n",
    "     ATE_Propensity=ATEPropensity(\"T\",\"Y\", \"propensity\")(values),\n",
    "     ATE_Impute=ATEImpute(\"T\",\"Y\",[\"U\"])(values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95794a46-4cd9-4388-a118-01029e6cc7ef",
   "metadata": {},
   "source": [
    "## Information Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a498f3-1b25-4f88-8256-ce644c4c3feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 18:57:59,643 - INFO - U : f(['N'])\n",
      "2025-07-18 18:57:59,645 - INFO - T : f(['N', 'U'])\n",
      "2025-07-18 18:57:59,647 - INFO - Y : f(['N', 'U', 'T'])\n",
      "2025-07-18 18:57:59,648 - INFO - Leakage : f(['N', 'T', 'Y'])\n",
      "2025-07-18 18:57:59,649 - INFO - fitting model for propensity: 'propensity'\n",
      "2025-07-18 18:57:59,864 - INFO - fitting model for propensity: 'propensity_leakage'\n",
      "2025-07-18 18:58:00,139 - INFO - fitting model for imputation\n",
      "2025-07-18 18:58:00,258 - INFO - fitting model for imputation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "      <th>ATE_Propensity</th>\n",
       "      <th>ATE_Impute</th>\n",
       "      <th>ATE_Propensity_Leakage</th>\n",
       "      <th>ATE_Impute_Leakage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.688751</td>\n",
       "      <td>0.489988</td>\n",
       "      <td>0.489974</td>\n",
       "      <td>0.504171</td>\n",
       "      <td>0.435761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Naive  ATE_Propensity  ATE_Impute  ATE_Propensity_Leakage  \\\n",
       "0  0.688751        0.489988    0.489974                0.504171   \n",
       "\n",
       "   ATE_Impute_Leakage  \n",
       "0            0.435761  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCM = {\n",
    "    \"U\" : lambda N: (torch.rand(N) < 0.5)*1.0,\n",
    "    \"T\" : lambda N, U: (torch.rand(N) < (0.1 + 0.4*U))*1.0,\n",
    "    \"Y\" : lambda N, U, T: (torch.rand(N) < (0.1 + 0.4*U  + 0.5*T))*1.0,\n",
    "    \"Leakage\" : lambda N, T, Y: (T+Y) * (torch.rand(N) < 0.3) \n",
    "}\n",
    "\n",
    "values = eval_scm(SCM, 10000)\n",
    "enrich_propensity(values, \"T\", [\"U\"], \"propensity\", model=GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3))\n",
    "enrich_propensity(values, \"T\", [\"U\",\"Leakage\"], \"propensity_leakage\", model=GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3))\n",
    "\n",
    "mgen = lambda: GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "show(Naive=CondMeanDiff(\"T\",\"Y\")(values),\n",
    "     ATE_Propensity=ATEPropensity(\"T\",\"Y\", \"propensity\")(values),\n",
    "     ATE_Impute=ATEImpute(\"T\",\"Y\",[\"U\"], mgen=mgen)(values),\n",
    "     ATE_Propensity_Leakage=ATEPropensity(\"T\",\"Y\", \"propensity_leakage\")(values),\n",
    "     ATE_Impute_Leakage=ATEImpute(\"T\",\"Y\",[\"U\",\"Leakage\"], mgen=mgen)(values))\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013328e8-ac42-453f-a164-69f103cbe862",
   "metadata": {},
   "source": [
    "## Bidirectional Causality\n",
    "\n",
    "Movie A can appear before or after Movie B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caa911bd-2c68-4051-86e3-edd24e0db5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 18:58:00,409 - INFO - R1 : f(['N'])\n",
      "2025-07-18 18:58:00,413 - INFO - R2 : f(['N'])\n",
      "2025-07-18 18:58:00,413 - INFO - U : f(['N'])\n",
      "2025-07-18 18:58:00,413 - INFO - A1 : f(['N', 'U', 'R1'])\n",
      "2025-07-18 18:58:00,413 - INFO - B : f(['N', 'U', 'A1', 'R2'])\n",
      "2025-07-18 18:58:00,413 - INFO - A2 : f(['N', 'U', 'A1', 'B'])\n",
      "2025-07-18 18:58:00,413 - INFO - A : f(['A1', 'A2'])\n",
      "2025-07-18 18:58:00,423 - INFO - Calculating ground truth\n",
      "2025-07-18 18:58:00,423 - INFO - DO A1\n",
      "2025-07-18 18:58:00,424 - INFO - A1 : f(['N'])\n",
      "2025-07-18 18:58:00,424 - INFO - B : f(['N', 'U', 'A1', 'R2'])\n",
      "2025-07-18 18:58:00,427 - INFO - A2 : f(['N', 'U', 'A1', 'B'])\n",
      "2025-07-18 18:58:00,428 - INFO - A : f(['A1', 'A2'])\n",
      "2025-07-18 18:58:00,428 - INFO - DO A1\n",
      "2025-07-18 18:58:00,428 - INFO - A1 : f(['N'])\n",
      "2025-07-18 18:58:00,428 - INFO - B : f(['N', 'U', 'A1', 'R2'])\n",
      "2025-07-18 18:58:00,433 - INFO - A2 : f(['N', 'U', 'A1', 'B'])\n",
      "2025-07-18 18:58:00,433 - INFO - A : f(['A1', 'A2'])\n",
      "2025-07-18 18:58:00,433 - INFO - fitting model for propensity: 'propensity'\n",
      "2025-07-18 18:58:00,483 - INFO - fitting model for propensity: 'propensity_alt'\n",
      "2025-07-18 18:58:00,544 - INFO - fitting model for imputation\n",
      "2025-07-18 18:58:01,347 - INFO - fitting model for imputation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GroundTruth</th>\n",
       "      <th>Naive</th>\n",
       "      <th>ATE_Stratified</th>\n",
       "      <th>ATE_Propensity</th>\n",
       "      <th>ATE_Impute</th>\n",
       "      <th>ATE_Propensity_Alt</th>\n",
       "      <th>ATE_Propensity_Filtered</th>\n",
       "      <th>ATE_Impute_TisA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.39976</td>\n",
       "      <td>0.590412</td>\n",
       "      <td>0.39715</td>\n",
       "      <td>0.397218</td>\n",
       "      <td>0.397146</td>\n",
       "      <td>0.330134</td>\n",
       "      <td>0.611673</td>\n",
       "      <td>0.498513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GroundTruth     Naive  ATE_Stratified  ATE_Propensity  ATE_Impute  \\\n",
       "0      0.39976  0.590412         0.39715        0.397218    0.397146   \n",
       "\n",
       "   ATE_Propensity_Alt  ATE_Propensity_Filtered  ATE_Impute_TisA  \n",
       "0            0.330134                 0.611673         0.498513  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SCM = {\n",
    "    \"R1\" : lambda N: torch.rand(N),\n",
    "    \"R2\" : lambda N: torch.rand(N),\n",
    "    \"U\" :  lambda N: (torch.rand(N) < 0.5)*1.0,\n",
    "    \"A1\":  lambda N, U, R1: (R1 < (0.1 + 0.4*U))*1.0,\n",
    "    \"B\" :  lambda N, U, A1, R2: (R2 < (0.1 + 0.4*U + 0.4*A1))*1.0,\n",
    "    \"A2\":  lambda N, U, A1, B: torch.where(A1>0.5, torch.zeros(N), (torch.rand(N) < (0.1 + 0.4*U + 0.4*B))*1.0),\n",
    "    \"A\" :  lambda A1, A2: (A1+A2 > 0.5) * 1.0\n",
    "}\n",
    "\n",
    "values = eval_scm(SCM, 100000)\n",
    "\n",
    "ground_truth = ground_truth_ate(SCM, values, \"A1\",\"B\")\n",
    "\n",
    "enrich_propensity(values, \"A1\", [\"U\"])\n",
    "enrich_propensity(values, \"A\", [\"U\"], \"propensity_alt\")\n",
    "\n",
    "\n",
    "show(GroundTruth=ground_truth, \n",
    "     Naive=CondMeanDiff(\"A1\",\"B\")(values),\n",
    "     ATE_Stratified=ATEStratified(\"A1\",\"B\", SplitStratify(\"U\",[0.5]))(values),\n",
    "     ATE_Propensity=ATEPropensity(\"A1\",\"B\", \"propensity\")(values),\n",
    "     ATE_Impute=ATEImpute(\"A1\",\"B\",[\"U\"])(values),\n",
    "     ATE_Propensity_Alt=ATEPropensity(\"A1\",\"B\", \"propensity_alt\")(values),\n",
    "     ATE_Propensity_Filtered=ATEPropensity(\"A\",\"B\", \"propensity\")(apply_filter(values, (values[\"A2\"] < 0.5))),\n",
    "     ATE_Impute_TisA=ATEImpute(\"A\",\"B\",[\"U\"])(values),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c76a3a7-7561-49ae-b7bc-49adf3d12f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0699ad0c-f423-49e3-b109-06010f61ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950accbf-3b6d-4b12-9254-16f9afffcbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc813d-0ea3-4be5-8059-35ef2e20a7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
